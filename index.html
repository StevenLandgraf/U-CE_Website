<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">

  <!-- Meta tags for search engines and social media -->
  <meta name="description" content="U-CE is a novel Uncertainty-aware Cross-Entropy loss function for semantic segmentation that dynamically incorporates predictive uncertainty into training via pixel-wise loss weighting.">
  <meta name="keywords" content="semantic segmentation, uncertainty estimation, cross-entropy loss, Monte Carlo Dropout, calibration, uncertainty-aware training, Cityscapes, ACDC, U-CE, robustness, reliability, safety-critical AI">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Open Graph (Facebook, LinkedIn, etc.) -->
  <meta property="og:title" content="U-CE: Uncertainty-aware Cross-Entropy for Semantic Segmentation" />
  <meta property="og:description" content="We propose U-CE, an uncertainty-aware loss for semantic segmentation that improves both segmentation performance and uncertainty estimation by integrating Monte Carlo Dropout-based uncertainties into the cross-entropy loss." />
  <meta property="og:url" content="https://stevenlandgraf.github.io/U-CE_Website/" />
  <meta property="og:image" content="static/images/icon.png" />
  <meta property="og:image:width" content="512" />
  <meta property="og:image:height" content="512" />
  <meta property="og:type" content="website" />

  <title>U-CE: Uncertainty-aware Cross-Entropy for Semantic Segmentation</title>
  <link rel="icon" type="image/x-icon" href="static/images/icon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">U-CE: Uncertainty-aware Cross-Entropy for Semantic Segmentation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=7DOqcXkAAAAJ&hl=en" target="_blank">Steven Landgraf</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=_qfDWfUAAAAJ&hl=en" target="_blank">Markus Hillemann</a>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=P8p0BNcAAAAJ&hl=de" target="_blank">Kira Wursthorn</a>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=JutLoKsAAAAJ&hl=en" target="_blank">Markus Ulrich</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Machine Vision Metrology (MVM)<br>Institute of Photogrammetry and Remote Sensing (IPF)<br>Karlsruhe Institute of Technology (KIT)<br> ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences [2024]</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- PDF link -->
                      <span class="link-block">
                        <a href="https://isprs-annals.copernicus.org/articles/X-2-2024/129/2024/" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                  
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2307.09947" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                      </a>
                    </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/StevenLandgraf/U-CE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Deep neural networks have shown exceptional performance in various tasks, but their lack of robustness, reliability, and tendency to
          be overconfident pose challenges for their deployment in safety-critical applications like autonomous driving. In this regard, quantifying the uncertainty inherent to a model's prediction is a promising endeavour to address these shortcomings. In this work, we
          present a novel Uncertainty-aware Cross-Entropy loss (U-CE) that incorporates dynamic predictive uncertainties into the training
          process by pixel-wise weighting of the well-known cross-entropy loss (CE). Through extensive experimentation, we demonstrate
          the superiority of U-CE over regular CE training on two benchmark datasets, Cityscapes and ACDC, using two common backbone
          architectures, ResNet-18 and ResNet-101. With U-CE, we manage to train models that not only improve their segmentation performance but also provide meaningful uncertainties after training. Consequently, we contribute to the development of more robust
          and reliable segmentation models, ultimately advancing the state-of-the-art in safety-critical applications and beyond.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Methodology Section -->
<section class="section hero is-small">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Methodology</h2>
    <div class="columns is-centered">
      <div class="column is-full has-text-centered">
        <img src="static/images/methodology.png" alt="U-CE Method Overview" style="max-width: 100%; height: auto;" />
        <div class="content has-text-justified">
          <p>
            A schematic overview of the training process of U-CE. U-CE integrates the predictive uncertainties of a Monte Carlo Dropout
            (MC-Dropout) model into the training process to enhance segmentation performance. In comparison to most applications of Monte Carlo
            Dropout, U-CE utilizes the uncertainties not only at test time but also dynamically during training by applying pixel-wise weighting to the
            regular cross-entropy loss.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Quantitative Results Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Quantitative Results</h2>
    <div class="columns is-centered">
      <div class="column is-full has-text-centered">
        <img src="static/images/quantitative_results.png" style="max-width: 100%; height: auto;" />
        <div class="content has-text-justified">
          <p>
            A detailed quantitative comparison between regular
            CE and U-CE on the Cityscapes dataset using a dropout ratio
            of 20%. The provided numbers represent the mIoU ↑, ECE ↓, and mUnc.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Qualitative Results Section -->
<section class="section hero is-small">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Qualitative Results</h2>
    <div class="columns is-centered">
      <div class="column is-full has-text-centered">
        <img src="static/images/qualitative_results.png" alt="Qualitative Examples" style="max-width: 100%; height: auto;" />
        <div class="content has-text-justified">
          <p>
          Example images from the Cityscapes and ACDC validation set (a), corresponding ground truth labels (b), the model's segmentation predictions (c), a binary accuracy map (d), and the predictive uncertainty (e). White pixels in the binary accuracy map are either
          incorrect predictions or void classes, which appear black in the ground truth label. For the uncertainty prediction, brighter pixels represent
          higher predictive uncertainties. The first three rows depict results from models with a ResNet-18 backbone and dropout ratio of 20%,
          trained for 200 epochs on Cityscapes. The last three rows show examples from models using a ResNet-101 backbone and a dropout
          ratio of 20%, trained for 500 epochs on the ACDC dataset.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper Conclusion -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Conclusion</h2>
        <div class="content has-text-justified">
          <p>
          In this paper, we introduced U-CE, a novel uncertainty-aware
          cross-entropy loss for semantic segmentation. U-CE incorporates predictive uncertainties, based on Monte Carlo Dropout,
          into the training process through pixel-wise weighting of the
          regular cross-entropy loss. As a result, we manage to train
          models that are naturally capable of predicting meaningful uncertainties after training while simultaneously improving their
          segmentation performance. Through extensive experimentation
          on the Cityscapes and ACDC datasets using ResNet-18 and
          ResNet-101 architectures, we demonstrated the superiority of
          U-CE over regular cross-entropy training.
          We hope that U-CE and our thorough discussion of potential
          limitations and future work contribute to the development of
          more robust and trustworthy segmentation models, ultimately
          advancing the state-of-the-art in safety-critical applications and
          beyond.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper conclusion -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{landgraf2023u,
  title={U-CE: Uncertainty-aware cross-entropy for semantic segmentation},
  author={Landgraf, Steven and Hillemann, Markus and Wursthorn, Kira and Ulrich, Markus},
  journal={arXiv preprint arXiv:2307.09947},
  year={2023}
}
</code></pre>
    </div>
</section>
<!--End BibTex citation -->
  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

  </body>
  </html>
